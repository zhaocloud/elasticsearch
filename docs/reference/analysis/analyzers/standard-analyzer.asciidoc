[[analysis-standard-analyzer]]
=== Standard Analyzer

An analyzer of type `standard` is built using the
<<analysis-standard-tokenizer,Standard
Tokenizer>> with the
<<analysis-standard-tokenfilter,Standard
Token Filter>>,
<<analysis-lowercase-tokenfilter,Lower
Case Token Filter>>, and
<<analysis-stop-tokenfilter,Stop
Token Filter>>.

The following are settings that can be set for a `standard` analyzer
type:

[cols="<,<",options="header",]
|=======================================================================
|Setting |Description
|`stopwords` |A list of stopwords to initialize the stop filter with.
<<<<<<< HEAD
Defaults to an 'empty' stopword list added[1.0.0.Beta1, Previously 
defaulted to the English stopwords list]. Check
<<analysis-stop-analyzer,Stop Analyzer>> for more details.
|`max_token_length` |The maximum token length. If a token is seen that
exceeds this length then it is discarded. Defaults to `255`.
=======
Defaults to an 'empty' stopword list Check
<<analysis-stop-analyzer,Stop Analyzer>> for more details.
|`max_token_length` |The maximum token length. If a token is seen that exceeds
this length then it is split at `max_token_length` intervals. Defaults to `255`.
>>>>>>> v2.1.1
|=======================================================================

